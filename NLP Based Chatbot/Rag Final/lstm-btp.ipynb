{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10608023,"sourceType":"datasetVersion","datasetId":6566879}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom torch.utils.data import DataLoader, TensorDataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T16:55:50.674501Z","iopub.execute_input":"2025-01-29T16:55:50.674934Z","iopub.status.idle":"2025-01-29T16:55:56.246347Z","shell.execute_reply.started":"2025-01-29T16:55:50.674899Z","shell.execute_reply":"2025-01-29T16:55:56.245343Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/greetings/greetings.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T16:55:56.247754Z","iopub.execute_input":"2025-01-29T16:55:56.248327Z","iopub.status.idle":"2025-01-29T16:55:56.274984Z","shell.execute_reply.started":"2025-01-29T16:55:56.248294Z","shell.execute_reply":"2025-01-29T16:55:56.273849Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T16:55:56.277542Z","iopub.execute_input":"2025-01-29T16:55:56.277974Z","iopub.status.idle":"2025-01-29T16:55:56.316203Z","shell.execute_reply.started":"2025-01-29T16:55:56.277940Z","shell.execute_reply":"2025-01-29T16:55:56.314916Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                              Question Label\n0    If we take up a 6 months internship, like othe...    No\n1    Can we do a 6 month internship without droppin...    No\n2    Can we do internship and in parallel register ...    No\n3          Are external BTP/IP collaborations allowed?    No\n4    Can a B.Tech. student do BTP with a guest or a...    No\n..                                                 ...   ...\n223                 Hey, how’s everything on your end?   Yes\n224              Hello, hope today’s been kind to you.   Yes\n225                   Hi, how are things going lately?   Yes\n226                      What’s been keeping you busy?   Yes\n227            Hi there, how’s the world treating you?   Yes\n\n[228 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Question</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>If we take up a 6 months internship, like othe...</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Can we do a 6 month internship without droppin...</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Can we do internship and in parallel register ...</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Are external BTP/IP collaborations allowed?</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Can a B.Tech. student do BTP with a guest or a...</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>223</th>\n      <td>Hey, how’s everything on your end?</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>224</th>\n      <td>Hello, hope today’s been kind to you.</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>225</th>\n      <td>Hi, how are things going lately?</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>226</th>\n      <td>What’s been keeping you busy?</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>227</th>\n      <td>Hi there, how’s the world treating you?</td>\n      <td>Yes</td>\n    </tr>\n  </tbody>\n</table>\n<p>228 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"print(df['Label'].isnull().sum())  # Check for NaNs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T16:55:56.318214Z","iopub.execute_input":"2025-01-29T16:55:56.318636Z","iopub.status.idle":"2025-01-29T16:55:56.327119Z","shell.execute_reply.started":"2025-01-29T16:55:56.318594Z","shell.execute_reply":"2025-01-29T16:55:56.326008Z"}},"outputs":[{"name":"stdout","text":"0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"df['Label'] = df['Label'].map({'Yes': 1, 'No': 0})\n\n# Text vectorization using TF-IDF\nvectorizer = TfidfVectorizer(max_features=50)\nX_tfidf = vectorizer.fit_transform(df['Question']).toarray()\n\n# Convert to 3D tensor (batch_size, seq_length, feature_size)\nX_data = np.expand_dims(X_tfidf, axis=1)  # seq_length=1\n\n# Convert to PyTorch tensors\nX_tensor = torch.tensor(X_data, dtype=torch.float32)\ny_tensor = torch.tensor(df['Label'].values, dtype=torch.long)\n\n# Split into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2,shuffle = True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T16:55:56.328318Z","iopub.execute_input":"2025-01-29T16:55:56.328694Z","iopub.status.idle":"2025-01-29T16:55:56.437103Z","shell.execute_reply.started":"2025-01-29T16:55:56.328654Z","shell.execute_reply":"2025-01-29T16:55:56.435952Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"print(y_tensor.unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T16:55:56.438116Z","iopub.execute_input":"2025-01-29T16:55:56.438515Z","iopub.status.idle":"2025-01-29T16:55:56.479937Z","shell.execute_reply.started":"2025-01-29T16:55:56.438463Z","shell.execute_reply":"2025-01-29T16:55:56.478732Z"}},"outputs":[{"name":"stdout","text":"tensor([0, 1])\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Create DataLoader\ntrain_dataset = TensorDataset(X_train, y_train)\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T16:55:56.481024Z","iopub.execute_input":"2025-01-29T16:55:56.481410Z","iopub.status.idle":"2025-01-29T16:55:56.486561Z","shell.execute_reply.started":"2025-01-29T16:55:56.481372Z","shell.execute_reply":"2025-01-29T16:55:56.485555Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class LSTMClassifier(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, output_size):\n        super(LSTMClassifier, self).__init__()\n        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_size, output_size)\n\n    def forward(self, x):\n        h0 = torch.zeros(2, x.size(0), 64).to(x.device)\n        c0 = torch.zeros(2, x.size(0), 64).to(x.device)\n        out, _ = self.lstm(x, (h0, c0))\n        out = self.fc(out[:, -1, :])\n        return out\n\n# Model parameters\ninput_size = 50  # Same as max_features in TF-IDF\nhidden_size = 64\nnum_layers = 2\noutput_size = 2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T16:55:56.487868Z","iopub.execute_input":"2025-01-29T16:55:56.488148Z","iopub.status.idle":"2025-01-29T16:55:56.509189Z","shell.execute_reply.started":"2025-01-29T16:55:56.488125Z","shell.execute_reply":"2025-01-29T16:55:56.507939Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Instantiate model, loss, and optimizer\nmodel = LSTMClassifier(input_size, hidden_size, num_layers, output_size)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Train the model\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    for batch_X, batch_y in train_loader:\n        optimizer.zero_grad()\n        outputs = model(batch_X)\n        print(batch_y)\n        loss = criterion(outputs, batch_y)\n        loss.backward()\n        optimizer.step()\n    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T16:55:56.511925Z","iopub.execute_input":"2025-01-29T16:55:56.512237Z","iopub.status.idle":"2025-01-29T16:56:00.043109Z","shell.execute_reply.started":"2025-01-29T16:55:56.512211Z","shell.execute_reply":"2025-01-29T16:56:00.041961Z"}},"outputs":[{"name":"stdout","text":"tensor([0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1])\ntensor([1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1])\ntensor([0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1])\ntensor([1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0])\ntensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1])\ntensor([1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1])\ntensor([1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0])\ntensor([1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1])\ntensor([1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0])\ntensor([0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0])\ntensor([0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0])\ntensor([0, 0, 0, 1, 1, 1])\nEpoch [1/10], Loss: 0.6928876042366028\ntensor([1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1])\ntensor([0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0])\ntensor([0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0])\ntensor([1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0])\ntensor([0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1])\ntensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0])\ntensor([0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1])\ntensor([1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0])\ntensor([1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1])\ntensor([1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1])\ntensor([1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0])\ntensor([1, 1, 1, 0, 0, 1])\nEpoch [2/10], Loss: 0.690507709980011\ntensor([1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1])\ntensor([1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1])\ntensor([0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1])\ntensor([1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1])\ntensor([1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1])\ntensor([1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1])\ntensor([1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0])\ntensor([0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1])\ntensor([1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0])\ntensor([0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0])\ntensor([0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1])\ntensor([0, 1, 1, 1, 1, 1])\nEpoch [3/10], Loss: 0.6494730114936829\ntensor([0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1])\ntensor([0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1])\ntensor([0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1])\ntensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1])\ntensor([0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1])\ntensor([1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1])\ntensor([1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0])\ntensor([1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1])\ntensor([1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1])\ntensor([1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0])\ntensor([1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1])\ntensor([0, 0, 0, 1, 1, 0])\nEpoch [4/10], Loss: 0.7106726169586182\ntensor([1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1])\ntensor([1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1])\ntensor([1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1])\ntensor([0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1])\ntensor([0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0])\ntensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\ntensor([0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0])\ntensor([1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1])\ntensor([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0])\ntensor([1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0])\ntensor([0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0])\ntensor([1, 1, 1, 0, 0, 1])\nEpoch [5/10], Loss: 0.572763204574585\ntensor([1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1])\ntensor([0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0])\ntensor([0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1])\ntensor([1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1])\ntensor([1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1])\ntensor([0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1])\ntensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0])\ntensor([1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0])\ntensor([0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0])\ntensor([1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0])\ntensor([1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0])\ntensor([0, 0, 0, 1, 0, 0])\nEpoch [6/10], Loss: 0.7932597994804382\ntensor([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0])\ntensor([0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1])\ntensor([1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1])\ntensor([1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1])\ntensor([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1])\ntensor([1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1])\ntensor([0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0])\ntensor([0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1])\ntensor([1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1])\ntensor([0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0])\ntensor([0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0])\ntensor([1, 0, 1, 1, 1, 0])\nEpoch [7/10], Loss: 0.39778828620910645\ntensor([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1])\ntensor([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1])\ntensor([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1])\ntensor([0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0])\ntensor([0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1])\ntensor([1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1])\ntensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0])\ntensor([1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1])\ntensor([1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0])\ntensor([0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1])\ntensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1])\ntensor([1, 1, 0, 1, 1, 0])\nEpoch [8/10], Loss: 0.2787599265575409\ntensor([1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1])\ntensor([1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1])\ntensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0])\ntensor([0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1])\ntensor([1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0])\ntensor([1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1])\ntensor([0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0])\ntensor([0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1])\ntensor([0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1])\ntensor([1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0])\ntensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1])\ntensor([0, 1, 1, 1, 0, 0])\nEpoch [9/10], Loss: 0.2573886811733246\ntensor([1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1])\ntensor([1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0])\ntensor([1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1])\ntensor([1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1])\ntensor([1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1])\ntensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0])\ntensor([1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1])\ntensor([1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0])\ntensor([0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0])\ntensor([1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1])\ntensor([0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1])\ntensor([1, 1, 0, 0, 1, 0])\nEpoch [10/10], Loss: 0.14335034787654877\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"model.eval()\nwith torch.no_grad():\n    test_outputs = model(X_test)\n    predicted_labels = torch.argmax(test_outputs, dim=1)\n    accuracy = (predicted_labels == y_test).sum().item() / y_test.size(0)\n    print(f'Accuracy: {accuracy * 100:.2f}%')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T16:56:00.044355Z","iopub.execute_input":"2025-01-29T16:56:00.044933Z","iopub.status.idle":"2025-01-29T16:56:00.066013Z","shell.execute_reply.started":"2025-01-29T16:56:00.044898Z","shell.execute_reply":"2025-01-29T16:56:00.064731Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 97.83%\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"torch.save(model.state_dict(), \"lstm_text_classifier.pth\")\nprint(\"Model saved successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:04:48.473095Z","iopub.execute_input":"2025-01-29T17:04:48.473673Z","iopub.status.idle":"2025-01-29T17:04:48.484165Z","shell.execute_reply.started":"2025-01-29T17:04:48.473635Z","shell.execute_reply":"2025-01-29T17:04:48.482935Z"}},"outputs":[{"name":"stdout","text":"Model saved successfully!\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"model_loaded = LSTMClassifier(input_size, hidden_size, num_layers, output_size)\nmodel_loaded.load_state_dict(torch.load(\"/kaggle/working/lstm_text_classifier.pth\"))\nmodel_loaded.eval()  # Set model to evaluation mode","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:05:42.798676Z","iopub.execute_input":"2025-01-29T17:05:42.799164Z","iopub.status.idle":"2025-01-29T17:05:42.816466Z","shell.execute_reply.started":"2025-01-29T17:05:42.799127Z","shell.execute_reply":"2025-01-29T17:05:42.814997Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-12-9425928f85f6>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model_loaded.load_state_dict(torch.load(\"/kaggle/working/lstm_text_classifier.pth\"))\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"LSTMClassifier(\n  (lstm): LSTM(50, 64, num_layers=2, batch_first=True)\n  (fc): Linear(in_features=64, out_features=2, bias=True)\n)"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"def predict(text, model, vectorizer):\n    model.eval()  # Set to evaluation mode\n\n    # Convert text to TF-IDF vector\n    text_vector = vectorizer.transform([text]).toarray()\n    text_tensor = torch.tensor(np.expand_dims(text_vector, axis=1), dtype=torch.float32)\n\n    # Get model prediction\n    with torch.no_grad():\n        output = model(text_tensor)\n        predicted_label = torch.argmax(output, dim=1).item()\n\n    return \"yes\" if predicted_label == 1 else \"no\"\n\n# Example usage\nnew_text = \"Hello, How are you?\"\npredicted_label = predict(new_text, model_loaded, vectorizer)\nprint(f\"Predicted Label: {predicted_label}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T17:27:15.082088Z","iopub.execute_input":"2025-01-29T17:27:15.082478Z","iopub.status.idle":"2025-01-29T17:27:15.092506Z","shell.execute_reply.started":"2025-01-29T17:27:15.082448Z","shell.execute_reply":"2025-01-29T17:27:15.091305Z"}},"outputs":[{"name":"stdout","text":"Predicted Label: yes\n","output_type":"stream"}],"execution_count":24}]}